ROBERT v 1.0.6 2024/06/06 09:48:42 
How to cite: Dalmau, D.; Alegre Requena, J. V. ChemRxiv, 2023, DOI: 10.26434/chemrxiv-2023-k994h

Command line used in ROBERT: python -m robert --y "dG_C5" --csv_name "bmc_dft_robert_input_NBOonly.csv" --names "Cofactor" --ignore "[Cofactor,dG_C4]" --train "[60,65,70,75,80,85,90]" --model "[NN,MVL,RF,GB]"


o  Starting generation of ML models with the GENERATE module

o  Database bmc_dft_robert_input_NBOonly_CURATE.csv loaded successfully, including:
   - 132 datapoints
   - 27 accepted descriptors
   - 2 ignored descriptors
   - 0 discarded descriptors

o  Starting heatmap scan with 4 ML models (['NN', 'MVL', 'RF', 'GB']) and 7 training sizes ([60, 65, 70, 75, 80, 85, 90]).
   Heatmap generation:
   - 1/168 - Training size: 60, ML model: NN, seed: 0 
   - 2/168 - Training size: 60, ML model: NN, seed: 8 
   - 3/168 - Training size: 60, ML model: NN, seed: 19 
   - 4/168 - Training size: 60, ML model: NN, seed: 43 
   - 5/168 - Training size: 60, ML model: NN, seed: 70 
   - 6/168 - Training size: 60, ML model: NN, seed: 233 
   - 7/168 - Training size: 60, ML model: MVL, seed: 0 
   - 8/168 - Training size: 60, ML model: MVL, seed: 8 
   - 9/168 - Training size: 60, ML model: MVL, seed: 19 
   - 10/168 - Training size: 60, ML model: MVL, seed: 43 
   - 11/168 - Training size: 60, ML model: MVL, seed: 70 
   - 12/168 - Training size: 60, ML model: MVL, seed: 233 
   - 13/168 - Training size: 60, ML model: RF, seed: 0 
   - 14/168 - Training size: 60, ML model: RF, seed: 8 
   - 15/168 - Training size: 60, ML model: RF, seed: 19 
   - 16/168 - Training size: 60, ML model: RF, seed: 43 
   - 17/168 - Training size: 60, ML model: RF, seed: 70 
   - 18/168 - Training size: 60, ML model: RF, seed: 233 
   - 19/168 - Training size: 60, ML model: GB, seed: 0 
   - 20/168 - Training size: 60, ML model: GB, seed: 8 
   - 21/168 - Training size: 60, ML model: GB, seed: 19 
   - 22/168 - Training size: 60, ML model: GB, seed: 43 
   - 23/168 - Training size: 60, ML model: GB, seed: 70 
   - 24/168 - Training size: 60, ML model: GB, seed: 233 
   - 25/168 - Training size: 65, ML model: NN, seed: 0 
   - 26/168 - Training size: 65, ML model: NN, seed: 8 
   - 27/168 - Training size: 65, ML model: NN, seed: 19 
   - 28/168 - Training size: 65, ML model: NN, seed: 43 
   - 29/168 - Training size: 65, ML model: NN, seed: 70 
   - 30/168 - Training size: 65, ML model: NN, seed: 233 
   - 31/168 - Training size: 65, ML model: MVL, seed: 0 
   - 32/168 - Training size: 65, ML model: MVL, seed: 8 
   - 33/168 - Training size: 65, ML model: MVL, seed: 19 
   - 34/168 - Training size: 65, ML model: MVL, seed: 43 
   - 35/168 - Training size: 65, ML model: MVL, seed: 70 
   - 36/168 - Training size: 65, ML model: MVL, seed: 233 
   - 37/168 - Training size: 65, ML model: RF, seed: 0 
   - 38/168 - Training size: 65, ML model: RF, seed: 8 
   - 39/168 - Training size: 65, ML model: RF, seed: 19 
   - 40/168 - Training size: 65, ML model: RF, seed: 43 
   - 41/168 - Training size: 65, ML model: RF, seed: 70 
   - 42/168 - Training size: 65, ML model: RF, seed: 233 
   - 43/168 - Training size: 65, ML model: GB, seed: 0 
   - 44/168 - Training size: 65, ML model: GB, seed: 8 
   - 45/168 - Training size: 65, ML model: GB, seed: 19 
   - 46/168 - Training size: 65, ML model: GB, seed: 43 
   - 47/168 - Training size: 65, ML model: GB, seed: 70 
   - 48/168 - Training size: 65, ML model: GB, seed: 233 
   - 49/168 - Training size: 70, ML model: NN, seed: 0 
   - 50/168 - Training size: 70, ML model: NN, seed: 8 
   - 51/168 - Training size: 70, ML model: NN, seed: 19 
   - 52/168 - Training size: 70, ML model: NN, seed: 43 
   - 53/168 - Training size: 70, ML model: NN, seed: 70 
   - 54/168 - Training size: 70, ML model: NN, seed: 233 
   - 55/168 - Training size: 70, ML model: MVL, seed: 0 
   - 56/168 - Training size: 70, ML model: MVL, seed: 8 
   - 57/168 - Training size: 70, ML model: MVL, seed: 19 
   - 58/168 - Training size: 70, ML model: MVL, seed: 43 
   - 59/168 - Training size: 70, ML model: MVL, seed: 70 
   - 60/168 - Training size: 70, ML model: MVL, seed: 233 
   - 61/168 - Training size: 70, ML model: RF, seed: 0 
   - 62/168 - Training size: 70, ML model: RF, seed: 8 
   - 63/168 - Training size: 70, ML model: RF, seed: 19 
   - 64/168 - Training size: 70, ML model: RF, seed: 43 
   - 65/168 - Training size: 70, ML model: RF, seed: 70 
   - 66/168 - Training size: 70, ML model: RF, seed: 233 
   - 67/168 - Training size: 70, ML model: GB, seed: 0 
   - 68/168 - Training size: 70, ML model: GB, seed: 8 
   - 69/168 - Training size: 70, ML model: GB, seed: 19 
   - 70/168 - Training size: 70, ML model: GB, seed: 43 
   - 71/168 - Training size: 70, ML model: GB, seed: 70 
   - 72/168 - Training size: 70, ML model: GB, seed: 233 
   - 73/168 - Training size: 75, ML model: NN, seed: 0 
   - 74/168 - Training size: 75, ML model: NN, seed: 8 
   - 75/168 - Training size: 75, ML model: NN, seed: 19 
   - 76/168 - Training size: 75, ML model: NN, seed: 43 
   - 77/168 - Training size: 75, ML model: NN, seed: 70 
   - 78/168 - Training size: 75, ML model: NN, seed: 233 
   - 79/168 - Training size: 75, ML model: MVL, seed: 0 
   - 80/168 - Training size: 75, ML model: MVL, seed: 8 
   - 81/168 - Training size: 75, ML model: MVL, seed: 19 
   - 82/168 - Training size: 75, ML model: MVL, seed: 43 
   - 83/168 - Training size: 75, ML model: MVL, seed: 70 
   - 84/168 - Training size: 75, ML model: MVL, seed: 233 
   - 85/168 - Training size: 75, ML model: RF, seed: 0 
   - 86/168 - Training size: 75, ML model: RF, seed: 8 
   - 87/168 - Training size: 75, ML model: RF, seed: 19 
   - 88/168 - Training size: 75, ML model: RF, seed: 43 
   - 89/168 - Training size: 75, ML model: RF, seed: 70 
   - 90/168 - Training size: 75, ML model: RF, seed: 233 
   - 91/168 - Training size: 75, ML model: GB, seed: 0 
   - 92/168 - Training size: 75, ML model: GB, seed: 8 
   - 93/168 - Training size: 75, ML model: GB, seed: 19 
   - 94/168 - Training size: 75, ML model: GB, seed: 43 
   - 95/168 - Training size: 75, ML model: GB, seed: 70 
   - 96/168 - Training size: 75, ML model: GB, seed: 233 
   - 97/168 - Training size: 80, ML model: NN, seed: 0 
   - 98/168 - Training size: 80, ML model: NN, seed: 8 
   - 99/168 - Training size: 80, ML model: NN, seed: 19 
   - 100/168 - Training size: 80, ML model: NN, seed: 43 
   - 101/168 - Training size: 80, ML model: NN, seed: 70 
   - 102/168 - Training size: 80, ML model: NN, seed: 233 
   - 103/168 - Training size: 80, ML model: MVL, seed: 0 
   - 104/168 - Training size: 80, ML model: MVL, seed: 8 
   - 105/168 - Training size: 80, ML model: MVL, seed: 19 
   - 106/168 - Training size: 80, ML model: MVL, seed: 43 
   - 107/168 - Training size: 80, ML model: MVL, seed: 70 
   - 108/168 - Training size: 80, ML model: MVL, seed: 233 
   - 109/168 - Training size: 80, ML model: RF, seed: 0 
   - 110/168 - Training size: 80, ML model: RF, seed: 8 
   - 111/168 - Training size: 80, ML model: RF, seed: 19 
   - 112/168 - Training size: 80, ML model: RF, seed: 43 
   - 113/168 - Training size: 80, ML model: RF, seed: 70 
   - 114/168 - Training size: 80, ML model: RF, seed: 233 
   - 115/168 - Training size: 80, ML model: GB, seed: 0 
   - 116/168 - Training size: 80, ML model: GB, seed: 8 
   - 117/168 - Training size: 80, ML model: GB, seed: 19 
   - 118/168 - Training size: 80, ML model: GB, seed: 43 
   - 119/168 - Training size: 80, ML model: GB, seed: 70 
   - 120/168 - Training size: 80, ML model: GB, seed: 233 
   - 121/168 - Training size: 85, ML model: NN, seed: 0 
   - 122/168 - Training size: 85, ML model: NN, seed: 8 
   - 123/168 - Training size: 85, ML model: NN, seed: 19 
   - 124/168 - Training size: 85, ML model: NN, seed: 43 
   - 125/168 - Training size: 85, ML model: NN, seed: 70 
   - 126/168 - Training size: 85, ML model: NN, seed: 233 
   - 127/168 - Training size: 85, ML model: MVL, seed: 0 
   - 128/168 - Training size: 85, ML model: MVL, seed: 8 
   - 129/168 - Training size: 85, ML model: MVL, seed: 19 
   - 130/168 - Training size: 85, ML model: MVL, seed: 43 
   - 131/168 - Training size: 85, ML model: MVL, seed: 70 
   - 132/168 - Training size: 85, ML model: MVL, seed: 233 
   - 133/168 - Training size: 85, ML model: RF, seed: 0 
   - 134/168 - Training size: 85, ML model: RF, seed: 8 
   - 135/168 - Training size: 85, ML model: RF, seed: 19 
   - 136/168 - Training size: 85, ML model: RF, seed: 43 
   - 137/168 - Training size: 85, ML model: RF, seed: 70 
   - 138/168 - Training size: 85, ML model: RF, seed: 233 
   - 139/168 - Training size: 85, ML model: GB, seed: 0 
   - 140/168 - Training size: 85, ML model: GB, seed: 8 
   - 141/168 - Training size: 85, ML model: GB, seed: 19 
   - 142/168 - Training size: 85, ML model: GB, seed: 43 
   - 143/168 - Training size: 85, ML model: GB, seed: 70 
   - 144/168 - Training size: 85, ML model: GB, seed: 233 
   - 145/168 - Training size: 90, ML model: NN, seed: 0 
   - 146/168 - Training size: 90, ML model: NN, seed: 8 
   - 147/168 - Training size: 90, ML model: NN, seed: 19 
   - 148/168 - Training size: 90, ML model: NN, seed: 43 
   - 149/168 - Training size: 90, ML model: NN, seed: 70 
   - 150/168 - Training size: 90, ML model: NN, seed: 233 
   - 151/168 - Training size: 90, ML model: MVL, seed: 0 
   - 152/168 - Training size: 90, ML model: MVL, seed: 8 
   - 153/168 - Training size: 90, ML model: MVL, seed: 19 
   - 154/168 - Training size: 90, ML model: MVL, seed: 43 
   - 155/168 - Training size: 90, ML model: MVL, seed: 70 
   - 156/168 - Training size: 90, ML model: MVL, seed: 233 
   - 157/168 - Training size: 90, ML model: RF, seed: 0 

x  There is an error in the hyperopt module, 1) are you using type ="clas" for regression y values instead of type="reg"? or 2) are you using very small partition sizes for validation sets (fix with train="[60,70]" for example)? or 3) bad allocation memory issue
   - 158/168 - Training size: 90, ML model: RF, seed: 8 

x  There is an error in the hyperopt module, 1) are you using type ="clas" for regression y values instead of type="reg"? or 2) are you using very small partition sizes for validation sets (fix with train="[60,70]" for example)? or 3) bad allocation memory issue
   - 159/168 - Training size: 90, ML model: RF, seed: 19 

x  There is an error in the hyperopt module, 1) are you using type ="clas" for regression y values instead of type="reg"? or 2) are you using very small partition sizes for validation sets (fix with train="[60,70]" for example)? or 3) bad allocation memory issue
   - 160/168 - Training size: 90, ML model: RF, seed: 43 

x  There is an error in the hyperopt module, 1) are you using type ="clas" for regression y values instead of type="reg"? or 2) are you using very small partition sizes for validation sets (fix with train="[60,70]" for example)? or 3) bad allocation memory issue
   - 161/168 - Training size: 90, ML model: RF, seed: 70 

x  There is an error in the hyperopt module, 1) are you using type ="clas" for regression y values instead of type="reg"? or 2) are you using very small partition sizes for validation sets (fix with train="[60,70]" for example)? or 3) bad allocation memory issue
   - 162/168 - Training size: 90, ML model: RF, seed: 233 

x  There is an error in the hyperopt module, 1) are you using type ="clas" for regression y values instead of type="reg"? or 2) are you using very small partition sizes for validation sets (fix with train="[60,70]" for example)? or 3) bad allocation memory issue
   - 163/168 - Training size: 90, ML model: GB, seed: 0 
   - 164/168 - Training size: 90, ML model: GB, seed: 8 
   - 165/168 - Training size: 90, ML model: GB, seed: 19 
   - 166/168 - Training size: 90, ML model: GB, seed: 43 
   - 167/168 - Training size: 90, ML model: GB, seed: 70 
   - 168/168 - Training size: 90, ML model: GB, seed: 233 

o  Heatmap ML models no PFI filter succesfully created in GENERATE/Raw_data

o  Heatmap ML models with PFI filter succesfully created in GENERATE/Raw_data

Time GENERATE: 414.91 seconds

